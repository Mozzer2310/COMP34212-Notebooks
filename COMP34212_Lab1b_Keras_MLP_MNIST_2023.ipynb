{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mozzer2310/COMP34212-Notebooks/blob/main/COMP34212_Lab1b_Keras_MLP_MNIST_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWWn1oMdMP0d"
      },
      "source": [
        "MLP for Complex Problems: The MNIST dataset\n",
        "=========\n",
        "\n",
        "\n",
        "In this exercise we will first learn to use the simple perceptron network (input-output layers only) and a Multi-Layer Perceptron (MLP, with one or more hidden layers). To make the task more interesting than the XOR problem, we will be using a more complex training set. This will be the MNIST dataset, a well known neural network problem for the recognition of the 10 handwritten characters from 0 to 9 ([MNIST](http://yann.lecun.com/exdb/mnist/)).\n",
        "\n",
        "This exercise is based on the  Gulli & Pal (2017) 'Deep Learning with Keras' textbook, with some additional code to help us understand and test the programme.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezwPEU5UMP0o"
      },
      "source": [
        "**Importing the libraries and defining the main training parameters**\n",
        "\n",
        "The initial code is necessary to prepare the data and the simulation (hyper)parameters.\n",
        "We first import numpy. In our case we will use it to create and pre-process the array of the training data sets. We then import a few functions from Keras (we used some of these in our previous XOR exercise). The matplotlib library will be used for visualising some MNIST images and the plot of the training results.\n",
        "\n",
        "The code also defines the variables for some of the main parameters used throughout this program. \n",
        "The random seed definition is also important to be able to repeat the same parameter configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YpM98ckGMP0u"
      },
      "outputs": [],
      "source": [
        "# import of numpy and keras libraries\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers.legacy import SGD\n",
        "from tensorflow.keras import utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# variables for network and training\n",
        "N_EPOCH = 200 # initially set at 200 ; you can change this later \n",
        "BATCH_SIZE = 128  \n",
        "VERBOSE = 1\n",
        "N_CLASSES = 10   # number of classes/categories of digits from 0 to 9, i.e. number of output units \n",
        "OPTIMIZER = SGD(learning_rate=0.1) # Stochastic gradient descent optimiser\n",
        "N_HIDDEN = 128   # number of hidden units\n",
        "VALIDATION_SPLIT=0.2 # proportion of the dataset used for validation, with remaining .8 for training \n",
        "\n",
        "#each 2D image consists of 28x28 values/pixels, which needs to be reshaped in a vector of 784 pixels\n",
        "RESHAPED = 784\n",
        "\n",
        "# random seed number to be used for reproducibility\n",
        "np.random.seed(1671)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rgZEImMMP08"
      },
      "source": [
        "**Preparing the MNIST dataset and visualising the input images**\n",
        "\n",
        "This part of the code prepares the input and output training set, and the corresponding test sets. \n",
        "It also visualises a sample image. The MNIST dataset is included in the Keras program and we do not need to use and external file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l4-TuW2_MP0-",
        "outputId": "4b94a849-1dc6-4a73-9ecb-8b0ade8d6c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Training data input shape:  (60000, 28, 28)\n",
            "Training data output shape:  (60000,)\n",
            "Test data input shape:  (10000, 28, 28)\n",
            "Test data ouput shape:  (10000,)\n",
            "Sample input image: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  67 232  39   0   0   0   0   0]\n",
            " [  0   0   0   0  62  81   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 120 180  39   0   0   0   0   0]\n",
            " [  0   0   0   0 126 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   2 153 210  40   0   0   0   0   0]\n",
            " [  0   0   0   0 220 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0  27 254 162   0   0   0   0   0   0]\n",
            " [  0   0   0   0 222 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 183 254 125   0   0   0   0   0   0]\n",
            " [  0   0   0  46 245 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 198 254  56   0   0   0   0   0   0]\n",
            " [  0   0   0 120 254 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   23 231 254  29   0   0   0   0   0   0]\n",
            " [  0   0   0 159 254 120   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  163 254 216  16   0   0   0   0   0   0]\n",
            " [  0   0   0 159 254  67   0   0   0   0   0   0   0   0   0  14  86 178\n",
            "  248 254  91   0   0   0   0   0   0   0]\n",
            " [  0   0   0 159 254  85   0   0   0  47  49 116 144 150 241 243 234 179\n",
            "  241 252  40   0   0   0   0   0   0   0]\n",
            " [  0   0   0 150 253 237 207 207 207 253 254 250 240 198 143  91  28   5\n",
            "  233 250   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 119 177 177 177 177 177  98  56   0   0   0   0   0 102\n",
            "  254 220   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254 137   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254  57   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254  57   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  255  94   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254  96   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254 153   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  255 153   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  96\n",
            "  254 153   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM30lEQVR4nO3dX4hc9RnG8eeJNiC2SqJ2WUzQtEShlGhLlGpFU2JDmpvYC4tBa0rFFaxgoRcVe1FBClpsS28sbFWS1tRSiKuh1LZpKNqCht1IqvljEhsS3SUmFZGmKLbRtxd70q5x58xm5pw5s/t+PzDMzHnnzLwc8uR3/szszxEhAHPfvKYbANAbhB1IgrADSRB2IAnCDiRxZi8/zDan/oGaRYSnW97VyG57te19tl+1fU837wWgXu70OrvtMyTtl/RlSeOSRiWti4g9JeswsgM1q2Nkv1LSqxFxMCL+LenXktZ28X4AatRN2C+U9PqU5+PFsg+xPWR7zPZYF58FoEu1n6CLiGFJwxK78UCTuhnZJyQtnvJ8UbEMQB/qJuyjkpbaXmJ7vqSbJG2ppi0AVet4Nz4iTti+S9IfJJ0h6bGI2F1ZZwAq1fGlt44+jGN2oHa1fKkGwOxB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBIdT9kM9LuVK1e2rG3atKl03euuu660vm/fvo56alJXYbd9SNJxSe9LOhERy6toCkD1qhjZvxQRb1bwPgBqxDE7kES3YQ9Jf7S9w/bQdC+wPWR7zPZYl58FoAvd7sZfExETtj8paavtVyLiuakviIhhScOSZDu6/DwAHepqZI+IieL+mKQRSVdW0RSA6nUcdttn2/7EyceSVknaVVVjAKrVzW78gKQR2yff51cR8ftKuqrBtddeW1o/77zzSusjIyNVtoMeuOKKK1rWRkdHe9hJf+g47BFxUNJlFfYCoEZcegOSIOxAEoQdSIKwA0kQdiCJND9xXbFiRWl96dKlpXUuvfWfefPKx6olS5a0rF100UWl6xaXlOcURnYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSCLNdfZbb721tP7888/3qBNUZXBwsLR+++23t6w9/vjjpeu+8sorHfXUzxjZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJNNfZ2/32GbPPI4880vG6Bw4cqLCT2YEEAEkQdiAJwg4kQdiBJAg7kARhB5Ig7EASc+Y6+7Jly0rrAwMDPeoEvXLuued2vO7WrVsr7GR2aDuy237M9jHbu6YsW2h7q+0Dxf2CetsE0K2Z7MZvkLT6lGX3SNoWEUslbSueA+hjbcMeEc9JeuuUxWslbSweb5R0Q7VtAahap8fsAxFxpHj8hqSWB8S2hyQNdfg5ACrS9Qm6iAjbUVIfljQsSWWvA1CvTi+9HbU9KEnF/bHqWgJQh07DvkXS+uLxeklPV9MOgLq03Y23/YSkFZLOtz0u6fuSHpD0G9u3STos6Wt1NjkTa9asKa2fddZZPeoEVWn33Yiy+dfbmZiY6Hjd2apt2CNiXYvSyop7AVAjvi4LJEHYgSQIO5AEYQeSIOxAEnPmJ66XXnppV+vv3r27ok5QlYceeqi03u7S3P79+1vWjh8/3lFPsxkjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kMWeus3drdHS06RZmpXPOOae0vnr1qX+r9P9uueWW0nVXrVrVUU8n3X///S1rb7/9dlfvPRsxsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAElxnLyxcuLCxz77ssstK67ZL69dff33L2qJFi0rXnT9/fmn95ptvLq3Pm1c+Xrz77rsta9u3by9d97333iutn3lm+T/fHTt2lNazYWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQcEb37MLu2D3v44YdL63fccUdpvd3vm1977bXTbWnGli1bVlpvd539xIkTLWvvvPNO6bp79uwprbe7Fj42NlZaf/bZZ1vWjh49Wrru+Ph4aX3BggWl9XbfIZirImLafzBtR3bbj9k+ZnvXlGX32Z6wvbO4lU+ODqBxM9mN3yBpuj838pOIuLy4/a7atgBUrW3YI+I5SW/1oBcANermBN1dtl8qdvNbHjzZHrI9Zrv84A5ArToN+88kfVrS5ZKOSPpRqxdGxHBELI+I5R1+FoAKdBT2iDgaEe9HxAeSfi7pymrbAlC1jsJue3DK069K2tXqtQD6Q9vfs9t+QtIKSefbHpf0fUkrbF8uKSQdklR+EbsH7rzzztL64cOHS+tXX311le2clnbX8J966qnS+t69e1vWXnjhhU5a6omhoaHS+gUXXFBaP3jwYJXtzHltwx4R66ZZ/GgNvQCoEV+XBZIg7EAShB1IgrADSRB2IIk0f0r6wQcfbLoFnGLlypVdrb958+aKOsmBkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkkhznR1zz8jISNMtzCqM7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEv2dH37JdWr/kkktK6/08XXUT2o7sthfb/rPtPbZ32767WL7Q9lbbB4r7BfW3C6BTM9mNPyHpOxHxGUlfkPQt25+RdI+kbRGxVNK24jmAPtU27BFxJCJeLB4fl7RX0oWS1kraWLxso6QbauoRQAVO65jd9sWSPidpu6SBiDhSlN6QNNBinSFJQ130CKACMz4bb/vjkjZL+nZE/HNqLSJCUky3XkQMR8TyiFjeVacAujKjsNv+mCaDvikiniwWH7U9WNQHJR2rp0UAVZjJ2XhLelTS3oj48ZTSFknri8frJT1dfXvILCJKb/PmzSu94cNmcsz+RUlfl/Sy7Z3FsnslPSDpN7Zvk3RY0tdq6RBAJdqGPSL+KqnVtxtWVtsOgLqwrwMkQdiBJAg7kARhB5Ig7EAS/MQVs9ZVV11VWt+wYUNvGpklGNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmus6NvtftT0jg9jOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATX2dGYZ555prR+44039qiTHBjZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJR0T5C+zFkn4haUBSSBqOiJ/avk/S7ZL+Ubz03oj4XZv3Kv8wAF2LiGn/EMBMwj4oaTAiXrT9CUk7JN2gyfnY/xURD820CcIO1K9V2GcyP/sRSUeKx8dt75V0YbXtAajbaR2z275Y0uckbS8W3WX7JduP2V7QYp0h22O2x7prFUA32u7G/++F9sclPSvpBxHxpO0BSW9q8jj+fk3u6n+zzXuwGw/UrONjdkmy/TFJv5X0h4j48TT1iyX9NiI+2+Z9CDtQs1Zhb7sb78k/8fmopL1Tg16cuDvpq5J2ddskgPrM5Gz8NZL+IullSR8Ui++VtE7S5ZrcjT8k6Y7iZF7ZezGyAzXraje+KoQdqF/Hu/EA5gbCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEr2esvlNSYenPD+/WNaP+rW3fu1LordOVdnbRa0KPf09+0c+3B6LiOWNNVCiX3vr174keutUr3pjNx5IgrADSTQd9uGGP79Mv/bWr31J9NapnvTW6DE7gN5pemQH0COEHUiikbDbXm17n+1Xbd/TRA+t2D5k+2XbO5uen66YQ++Y7V1Tli20vdX2geJ+2jn2GurtPtsTxbbbaXtNQ70ttv1n23ts77Z9d7G80W1X0ldPtlvPj9ltnyFpv6QvSxqXNCppXUTs6WkjLdg+JGl5RDT+BQzb10r6l6RfnJxay/YPJb0VEQ8U/1EuiIjv9klv9+k0p/GuqbdW04x/Qw1uuyqnP+9EEyP7lZJejYiDEfFvSb+WtLaBPvpeRDwn6a1TFq+VtLF4vFGT/1h6rkVvfSEijkTEi8Xj45JOTjPe6LYr6asnmgj7hZJen/J8XP0133tI+qPtHbaHmm5mGgNTptl6Q9JAk81Mo+003r10yjTjfbPtOpn+vFucoPuoayLi85K+Iulbxe5qX4rJY7B+unb6M0mf1uQcgEck/ajJZoppxjdL+nZE/HNqrcltN01fPdluTYR9QtLiKc8XFcv6QkRMFPfHJI1o8rCjnxw9OYNucX+s4X7+JyKORsT7EfGBpJ+rwW1XTDO+WdKmiHiyWNz4tpuur15ttybCPippqe0ltudLuknSlgb6+AjbZxcnTmT7bEmr1H9TUW+RtL54vF7S0w328iH9Mo13q2nG1fC2a3z684jo+U3SGk2ekf+7pO810UOLvj4l6W/FbXfTvUl6QpO7df/R5LmN2ySdJ2mbpAOS/iRpYR/19ktNTu39kiaDNdhQb9dochf9JUk7i9uaprddSV892W58XRZIghN0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DEfwHjYfAoH2KvwQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "# data: shuffled and split between train and test sets, loading and using the Keras mnist dataset\n",
        "(input_X_train, output_Y_train), (input_X_test, output_Y_test) = mnist.load_data()\n",
        "\n",
        "# print the shapes of the input and output data\n",
        "print(\"Training data input shape: \" , input_X_train.shape)\n",
        "print(\"Training data output shape: \" , output_Y_train.shape)\n",
        "print(\"Test data input shape: \" , input_X_test.shape)\n",
        "print(\"Test data ouput shape: \" , output_Y_test.shape)\n",
        "\n",
        "# visualisation of the numerical vector and plot of a selected image\n",
        "Selected_Image = 2\n",
        "image = input_X_train[Selected_Image]\n",
        "print (\"Sample input image: \" + str(image))\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show() \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDqNl3taMP1P"
      },
      "source": [
        "The input images now have to be reshaped as a linear vector. That is, we go from a 2D image of 28x28 pixels, to a linear vector of 784 (i.e. 28*28) pixels, to be passed as the 784 input units. Moreover, the initial pixel grey values given as type __int__ in the range 0-255 will be normalised to the __float32__ type in the range 0-1. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB15FrXOMP1R",
        "outputId": "62fe7eaa-c628-469f-8bc5-46e2839246f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data ready\n"
          ]
        }
      ],
      "source": [
        "# use 60000 images for training, 10000 for validation test\n",
        "input_X_train = input_X_train.reshape(60000, RESHAPED)\n",
        "input_X_test = input_X_test.reshape(10000, RESHAPED)\n",
        "input_X_train = input_X_train.astype('float32')\n",
        "input_X_test = input_X_test.astype('float32')\n",
        "\n",
        "# normalisation of the pixel values from 0-255 range to 0-1 range \n",
        "input_X_train /= 255\n",
        "input_X_test /= 255\n",
        "\n",
        "print (\"Input data ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsCwC5y7MP1Z"
      },
      "source": [
        "**Preparing the output labels**\n",
        "\n",
        "This code converts the output data into categorical (one-hot encoding) vectors of 0s and 1s.\n",
        "See example of the visualisation of the one-hot vector for the selected image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc4dgAqqMP1c",
        "outputId": "636a21df-6243-4c99-97a4-19c22fb4f5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot-vector: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# convert class vectors to binary class matrices\n",
        "output_Y_train = utils.to_categorical(output_Y_train, N_CLASSES)\n",
        "output_Y_test = utils.to_categorical(output_Y_test, N_CLASSES)\n",
        "\n",
        "# print the categorical, one-hot output vector for the sample image\n",
        "label = output_Y_train[Selected_Image]\n",
        "print (\"One-hot-vector: \" + str(label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-rcBfv8MP1q"
      },
      "source": [
        "Training the Simple Perceptron\n",
        "=========\n",
        "\n",
        "**Defining the network: Simple Perceptron**\n",
        "\n",
        "We will start by training a simple perceptron, i.e. a network with an input layer (the 784 input values/pixels) connected to the output layer (the 10 number classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTb4RC7zMP1s",
        "outputId": "ee682a15-852f-4569-8ff5-286a110f876b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                7850      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Defaults sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Dense layer for all to all connections\n",
        "# Define the output layer with 10 output units, and softmax activation as categorical output\n",
        "model.add(Dense(N_CLASSES, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Use categorical crossentropy for the loss evaluation, and the accuracy metrics\n",
        "# we previously chose the SGD optimiser in the OPTIMIZER variable definition  \n",
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
        "\n",
        "#show the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHyq0YoRMP1y"
      },
      "source": [
        "**Let's train the simple perceptron network**\n",
        "\n",
        "Let's now train (fit) the network with the above-defined batch size (128), and number of epochs (200). We save the training results into the history variable.\n",
        "\n",
        "Here we use the previous __VALIDATION_SPLIT=0.2__ definition to split the dataset into a 20% (0.2) validation set and the remaning 80% as training set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg3RCFukMP10",
        "outputId": "3cbdcf4d-7dee-4c8a-f70c-37382655ec37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "375/375 [==============================] - 10s 20ms/step - loss: 0.6259 - accuracy: 0.8448 - val_loss: 0.3974 - val_accuracy: 0.8954\n",
            "Epoch 2/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3946 - accuracy: 0.8932 - val_loss: 0.3478 - val_accuracy: 0.9054\n",
            "Epoch 3/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3585 - accuracy: 0.9005 - val_loss: 0.3282 - val_accuracy: 0.9090\n",
            "Epoch 4/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3398 - accuracy: 0.9056 - val_loss: 0.3154 - val_accuracy: 0.9141\n",
            "Epoch 5/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3278 - accuracy: 0.9085 - val_loss: 0.3076 - val_accuracy: 0.9143\n",
            "Epoch 6/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3191 - accuracy: 0.9114 - val_loss: 0.3010 - val_accuracy: 0.9155\n",
            "Epoch 7/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3125 - accuracy: 0.9131 - val_loss: 0.2978 - val_accuracy: 0.9176\n",
            "Epoch 8/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3074 - accuracy: 0.9148 - val_loss: 0.2940 - val_accuracy: 0.9181\n",
            "Epoch 9/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3028 - accuracy: 0.9153 - val_loss: 0.2913 - val_accuracy: 0.9192\n",
            "Epoch 10/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2993 - accuracy: 0.9168 - val_loss: 0.2881 - val_accuracy: 0.9200\n",
            "Epoch 11/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2961 - accuracy: 0.9174 - val_loss: 0.2871 - val_accuracy: 0.9195\n",
            "Epoch 12/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2934 - accuracy: 0.9179 - val_loss: 0.2839 - val_accuracy: 0.9210\n",
            "Epoch 13/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2907 - accuracy: 0.9181 - val_loss: 0.2830 - val_accuracy: 0.9228\n",
            "Epoch 14/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2887 - accuracy: 0.9193 - val_loss: 0.2817 - val_accuracy: 0.9219\n",
            "Epoch 15/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2868 - accuracy: 0.9202 - val_loss: 0.2802 - val_accuracy: 0.9221\n",
            "Epoch 16/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2850 - accuracy: 0.9202 - val_loss: 0.2793 - val_accuracy: 0.9223\n",
            "Epoch 17/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2832 - accuracy: 0.9205 - val_loss: 0.2779 - val_accuracy: 0.9222\n",
            "Epoch 18/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.9209 - val_loss: 0.2771 - val_accuracy: 0.9226\n",
            "Epoch 19/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.9218 - val_loss: 0.2769 - val_accuracy: 0.9227\n",
            "Epoch 20/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2791 - accuracy: 0.9220 - val_loss: 0.2764 - val_accuracy: 0.9237\n",
            "Epoch 21/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2780 - accuracy: 0.9222 - val_loss: 0.2747 - val_accuracy: 0.9239\n",
            "Epoch 22/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2767 - accuracy: 0.9234 - val_loss: 0.2749 - val_accuracy: 0.9242\n",
            "Epoch 23/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2757 - accuracy: 0.9231 - val_loss: 0.2745 - val_accuracy: 0.9240\n",
            "Epoch 24/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2746 - accuracy: 0.9233 - val_loss: 0.2733 - val_accuracy: 0.9248\n",
            "Epoch 25/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.9235 - val_loss: 0.2732 - val_accuracy: 0.9235\n",
            "Epoch 26/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2728 - accuracy: 0.9239 - val_loss: 0.2725 - val_accuracy: 0.9243\n",
            "Epoch 27/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2720 - accuracy: 0.9244 - val_loss: 0.2732 - val_accuracy: 0.9250\n",
            "Epoch 28/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2712 - accuracy: 0.9250 - val_loss: 0.2711 - val_accuracy: 0.9247\n",
            "Epoch 29/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2705 - accuracy: 0.9246 - val_loss: 0.2723 - val_accuracy: 0.9251\n",
            "Epoch 30/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2697 - accuracy: 0.9244 - val_loss: 0.2708 - val_accuracy: 0.9256\n",
            "Epoch 31/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2688 - accuracy: 0.9247 - val_loss: 0.2701 - val_accuracy: 0.9240\n",
            "Epoch 32/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.9254 - val_loss: 0.2701 - val_accuracy: 0.9249\n",
            "Epoch 33/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2674 - accuracy: 0.9251 - val_loss: 0.2695 - val_accuracy: 0.9267\n",
            "Epoch 34/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2670 - accuracy: 0.9258 - val_loss: 0.2705 - val_accuracy: 0.9251\n",
            "Epoch 35/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2662 - accuracy: 0.9261 - val_loss: 0.2697 - val_accuracy: 0.9262\n",
            "Epoch 36/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2658 - accuracy: 0.9262 - val_loss: 0.2697 - val_accuracy: 0.9256\n",
            "Epoch 37/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.9256 - val_loss: 0.2694 - val_accuracy: 0.9262\n",
            "Epoch 38/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2647 - accuracy: 0.9261 - val_loss: 0.2691 - val_accuracy: 0.9261\n",
            "Epoch 39/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2640 - accuracy: 0.9261 - val_loss: 0.2693 - val_accuracy: 0.9262\n",
            "Epoch 40/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2636 - accuracy: 0.9268 - val_loss: 0.2685 - val_accuracy: 0.9264\n",
            "Epoch 41/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2630 - accuracy: 0.9265 - val_loss: 0.2688 - val_accuracy: 0.9275\n",
            "Epoch 42/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2627 - accuracy: 0.9268 - val_loss: 0.2683 - val_accuracy: 0.9263\n",
            "Epoch 43/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2623 - accuracy: 0.9274 - val_loss: 0.2682 - val_accuracy: 0.9266\n",
            "Epoch 44/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2618 - accuracy: 0.9273 - val_loss: 0.2694 - val_accuracy: 0.9258\n",
            "Epoch 45/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2615 - accuracy: 0.9271 - val_loss: 0.2683 - val_accuracy: 0.9262\n",
            "Epoch 46/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.9278 - val_loss: 0.2684 - val_accuracy: 0.9265\n",
            "Epoch 47/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2603 - accuracy: 0.9276 - val_loss: 0.2679 - val_accuracy: 0.9265\n",
            "Epoch 48/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2602 - accuracy: 0.9273 - val_loss: 0.2679 - val_accuracy: 0.9261\n",
            "Epoch 49/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2598 - accuracy: 0.9278 - val_loss: 0.2679 - val_accuracy: 0.9262\n",
            "Epoch 50/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2594 - accuracy: 0.9278 - val_loss: 0.2672 - val_accuracy: 0.9272\n",
            "Epoch 51/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2590 - accuracy: 0.9274 - val_loss: 0.2673 - val_accuracy: 0.9273\n",
            "Epoch 52/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2588 - accuracy: 0.9277 - val_loss: 0.2669 - val_accuracy: 0.9273\n",
            "Epoch 53/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2581 - accuracy: 0.9282 - val_loss: 0.2679 - val_accuracy: 0.9270\n",
            "Epoch 54/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2581 - accuracy: 0.9280 - val_loss: 0.2668 - val_accuracy: 0.9283\n",
            "Epoch 55/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2577 - accuracy: 0.9283 - val_loss: 0.2669 - val_accuracy: 0.9270\n",
            "Epoch 56/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2573 - accuracy: 0.9283 - val_loss: 0.2672 - val_accuracy: 0.9276\n",
            "Epoch 57/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2569 - accuracy: 0.9286 - val_loss: 0.2673 - val_accuracy: 0.9274\n",
            "Epoch 58/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2568 - accuracy: 0.9282 - val_loss: 0.2663 - val_accuracy: 0.9267\n",
            "Epoch 59/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2563 - accuracy: 0.9290 - val_loss: 0.2665 - val_accuracy: 0.9277\n",
            "Epoch 60/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2558 - accuracy: 0.9287 - val_loss: 0.2672 - val_accuracy: 0.9266\n",
            "Epoch 61/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2558 - accuracy: 0.9284 - val_loss: 0.2666 - val_accuracy: 0.9279\n",
            "Epoch 62/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2554 - accuracy: 0.9285 - val_loss: 0.2676 - val_accuracy: 0.9269\n",
            "Epoch 63/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2552 - accuracy: 0.9295 - val_loss: 0.2667 - val_accuracy: 0.9272\n",
            "Epoch 64/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2549 - accuracy: 0.9291 - val_loss: 0.2666 - val_accuracy: 0.9283\n",
            "Epoch 65/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2545 - accuracy: 0.9292 - val_loss: 0.2666 - val_accuracy: 0.9283\n",
            "Epoch 66/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2543 - accuracy: 0.9288 - val_loss: 0.2660 - val_accuracy: 0.9277\n",
            "Epoch 67/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2539 - accuracy: 0.9292 - val_loss: 0.2664 - val_accuracy: 0.9291\n",
            "Epoch 68/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2538 - accuracy: 0.9290 - val_loss: 0.2672 - val_accuracy: 0.9273\n",
            "Epoch 69/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2538 - accuracy: 0.9290 - val_loss: 0.2657 - val_accuracy: 0.9285\n",
            "Epoch 70/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2531 - accuracy: 0.9295 - val_loss: 0.2679 - val_accuracy: 0.9272\n",
            "Epoch 71/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2531 - accuracy: 0.9294 - val_loss: 0.2657 - val_accuracy: 0.9278\n",
            "Epoch 72/200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2529 - accuracy: 0.9300 - val_loss: 0.2663 - val_accuracy: 0.9276\n",
            "Epoch 73/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2525 - accuracy: 0.9298 - val_loss: 0.2669 - val_accuracy: 0.9286\n",
            "Epoch 74/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2524 - accuracy: 0.9299 - val_loss: 0.2661 - val_accuracy: 0.9273\n",
            "Epoch 75/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2522 - accuracy: 0.9296 - val_loss: 0.2669 - val_accuracy: 0.9277\n",
            "Epoch 76/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2520 - accuracy: 0.9294 - val_loss: 0.2657 - val_accuracy: 0.9288\n",
            "Epoch 77/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2517 - accuracy: 0.9298 - val_loss: 0.2670 - val_accuracy: 0.9273\n",
            "Epoch 78/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2515 - accuracy: 0.9302 - val_loss: 0.2659 - val_accuracy: 0.9284\n",
            "Epoch 79/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2512 - accuracy: 0.9302 - val_loss: 0.2675 - val_accuracy: 0.9274\n",
            "Epoch 80/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2511 - accuracy: 0.9302 - val_loss: 0.2658 - val_accuracy: 0.9290\n",
            "Epoch 81/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2507 - accuracy: 0.9299 - val_loss: 0.2657 - val_accuracy: 0.9282\n",
            "Epoch 82/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2506 - accuracy: 0.9302 - val_loss: 0.2656 - val_accuracy: 0.9287\n",
            "Epoch 83/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2506 - accuracy: 0.9307 - val_loss: 0.2662 - val_accuracy: 0.9283\n",
            "Epoch 84/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2502 - accuracy: 0.9300 - val_loss: 0.2661 - val_accuracy: 0.9286\n",
            "Epoch 85/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2501 - accuracy: 0.9306 - val_loss: 0.2659 - val_accuracy: 0.9288\n",
            "Epoch 86/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2500 - accuracy: 0.9302 - val_loss: 0.2659 - val_accuracy: 0.9289\n",
            "Epoch 87/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2496 - accuracy: 0.9306 - val_loss: 0.2660 - val_accuracy: 0.9290\n",
            "Epoch 88/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2496 - accuracy: 0.9308 - val_loss: 0.2658 - val_accuracy: 0.9286\n",
            "Epoch 89/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2493 - accuracy: 0.9305 - val_loss: 0.2656 - val_accuracy: 0.9284\n",
            "Epoch 90/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2491 - accuracy: 0.9306 - val_loss: 0.2652 - val_accuracy: 0.9287\n",
            "Epoch 91/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2489 - accuracy: 0.9308 - val_loss: 0.2680 - val_accuracy: 0.9273\n",
            "Epoch 92/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2487 - accuracy: 0.9309 - val_loss: 0.2677 - val_accuracy: 0.9272\n",
            "Epoch 93/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2485 - accuracy: 0.9311 - val_loss: 0.2662 - val_accuracy: 0.9287\n",
            "Epoch 94/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2484 - accuracy: 0.9307 - val_loss: 0.2653 - val_accuracy: 0.9292\n",
            "Epoch 95/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2482 - accuracy: 0.9305 - val_loss: 0.2660 - val_accuracy: 0.9276\n",
            "Epoch 96/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2482 - accuracy: 0.9312 - val_loss: 0.2657 - val_accuracy: 0.9289\n",
            "Epoch 97/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2479 - accuracy: 0.9311 - val_loss: 0.2656 - val_accuracy: 0.9289\n",
            "Epoch 98/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2477 - accuracy: 0.9313 - val_loss: 0.2653 - val_accuracy: 0.9286\n",
            "Epoch 99/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2477 - accuracy: 0.9308 - val_loss: 0.2662 - val_accuracy: 0.9284\n",
            "Epoch 100/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2474 - accuracy: 0.9311 - val_loss: 0.2664 - val_accuracy: 0.9293\n",
            "Epoch 101/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2472 - accuracy: 0.9316 - val_loss: 0.2651 - val_accuracy: 0.9291\n",
            "Epoch 102/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2472 - accuracy: 0.9313 - val_loss: 0.2661 - val_accuracy: 0.9287\n",
            "Epoch 103/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2469 - accuracy: 0.9312 - val_loss: 0.2665 - val_accuracy: 0.9276\n",
            "Epoch 104/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2467 - accuracy: 0.9310 - val_loss: 0.2662 - val_accuracy: 0.9291\n",
            "Epoch 105/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2469 - accuracy: 0.9312 - val_loss: 0.2657 - val_accuracy: 0.9291\n",
            "Epoch 106/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2464 - accuracy: 0.9312 - val_loss: 0.2666 - val_accuracy: 0.9277\n",
            "Epoch 107/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2462 - accuracy: 0.9317 - val_loss: 0.2670 - val_accuracy: 0.9281\n",
            "Epoch 108/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2461 - accuracy: 0.9317 - val_loss: 0.2661 - val_accuracy: 0.9289\n",
            "Epoch 109/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2460 - accuracy: 0.9314 - val_loss: 0.2661 - val_accuracy: 0.9289\n",
            "Epoch 110/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2459 - accuracy: 0.9319 - val_loss: 0.2664 - val_accuracy: 0.9286\n",
            "Epoch 111/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2457 - accuracy: 0.9317 - val_loss: 0.2667 - val_accuracy: 0.9287\n",
            "Epoch 112/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2455 - accuracy: 0.9311 - val_loss: 0.2656 - val_accuracy: 0.9292\n",
            "Epoch 113/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2456 - accuracy: 0.9316 - val_loss: 0.2672 - val_accuracy: 0.9287\n",
            "Epoch 114/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2453 - accuracy: 0.9316 - val_loss: 0.2666 - val_accuracy: 0.9283\n",
            "Epoch 115/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2453 - accuracy: 0.9314 - val_loss: 0.2658 - val_accuracy: 0.9292\n",
            "Epoch 116/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2451 - accuracy: 0.9315 - val_loss: 0.2666 - val_accuracy: 0.9283\n",
            "Epoch 117/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2450 - accuracy: 0.9319 - val_loss: 0.2661 - val_accuracy: 0.9296\n",
            "Epoch 118/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.9323 - val_loss: 0.2663 - val_accuracy: 0.9286\n",
            "Epoch 119/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2448 - accuracy: 0.9319 - val_loss: 0.2667 - val_accuracy: 0.9293\n",
            "Epoch 120/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.9316 - val_loss: 0.2668 - val_accuracy: 0.9282\n",
            "Epoch 121/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2444 - accuracy: 0.9323 - val_loss: 0.2671 - val_accuracy: 0.9279\n",
            "Epoch 122/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2443 - accuracy: 0.9324 - val_loss: 0.2659 - val_accuracy: 0.9292\n",
            "Epoch 123/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2441 - accuracy: 0.9325 - val_loss: 0.2677 - val_accuracy: 0.9277\n",
            "Epoch 124/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2440 - accuracy: 0.9319 - val_loss: 0.2671 - val_accuracy: 0.9284\n",
            "Epoch 125/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2440 - accuracy: 0.9323 - val_loss: 0.2667 - val_accuracy: 0.9287\n",
            "Epoch 126/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2437 - accuracy: 0.9324 - val_loss: 0.2662 - val_accuracy: 0.9285\n",
            "Epoch 127/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2438 - accuracy: 0.9320 - val_loss: 0.2659 - val_accuracy: 0.9291\n",
            "Epoch 128/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2436 - accuracy: 0.9319 - val_loss: 0.2663 - val_accuracy: 0.9290\n",
            "Epoch 129/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2434 - accuracy: 0.9321 - val_loss: 0.2663 - val_accuracy: 0.9286\n",
            "Epoch 130/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2435 - accuracy: 0.9323 - val_loss: 0.2661 - val_accuracy: 0.9282\n",
            "Epoch 131/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2433 - accuracy: 0.9324 - val_loss: 0.2664 - val_accuracy: 0.9281\n",
            "Epoch 132/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2432 - accuracy: 0.9322 - val_loss: 0.2673 - val_accuracy: 0.9279\n",
            "Epoch 133/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2430 - accuracy: 0.9326 - val_loss: 0.2674 - val_accuracy: 0.9288\n",
            "Epoch 134/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2429 - accuracy: 0.9324 - val_loss: 0.2677 - val_accuracy: 0.9280\n",
            "Epoch 135/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2428 - accuracy: 0.9322 - val_loss: 0.2658 - val_accuracy: 0.9296\n",
            "Epoch 136/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2426 - accuracy: 0.9323 - val_loss: 0.2666 - val_accuracy: 0.9286\n",
            "Epoch 137/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2426 - accuracy: 0.9327 - val_loss: 0.2673 - val_accuracy: 0.9293\n",
            "Epoch 138/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2424 - accuracy: 0.9325 - val_loss: 0.2666 - val_accuracy: 0.9286\n",
            "Epoch 139/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2422 - accuracy: 0.9325 - val_loss: 0.2684 - val_accuracy: 0.9274\n",
            "Epoch 140/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2421 - accuracy: 0.9325 - val_loss: 0.2671 - val_accuracy: 0.9284\n",
            "Epoch 141/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2421 - accuracy: 0.9327 - val_loss: 0.2671 - val_accuracy: 0.9279\n",
            "Epoch 142/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2420 - accuracy: 0.9329 - val_loss: 0.2671 - val_accuracy: 0.9287\n",
            "Epoch 143/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 0.9324 - val_loss: 0.2675 - val_accuracy: 0.9274\n",
            "Epoch 144/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 0.9325 - val_loss: 0.2662 - val_accuracy: 0.9289\n",
            "Epoch 145/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2417 - accuracy: 0.9324 - val_loss: 0.2669 - val_accuracy: 0.9294\n",
            "Epoch 146/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2415 - accuracy: 0.9327 - val_loss: 0.2670 - val_accuracy: 0.9294\n",
            "Epoch 147/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2415 - accuracy: 0.9327 - val_loss: 0.2685 - val_accuracy: 0.9287\n",
            "Epoch 148/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2415 - accuracy: 0.9325 - val_loss: 0.2672 - val_accuracy: 0.9287\n",
            "Epoch 149/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2412 - accuracy: 0.9329 - val_loss: 0.2683 - val_accuracy: 0.9277\n",
            "Epoch 150/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2411 - accuracy: 0.9326 - val_loss: 0.2667 - val_accuracy: 0.9287\n",
            "Epoch 151/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.9333 - val_loss: 0.2676 - val_accuracy: 0.9287\n",
            "Epoch 152/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2410 - accuracy: 0.9331 - val_loss: 0.2677 - val_accuracy: 0.9288\n",
            "Epoch 153/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2408 - accuracy: 0.9329 - val_loss: 0.2673 - val_accuracy: 0.9289\n",
            "Epoch 154/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2409 - accuracy: 0.9332 - val_loss: 0.2676 - val_accuracy: 0.9280\n",
            "Epoch 155/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2408 - accuracy: 0.9327 - val_loss: 0.2672 - val_accuracy: 0.9283\n",
            "Epoch 156/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2406 - accuracy: 0.9330 - val_loss: 0.2677 - val_accuracy: 0.9276\n",
            "Epoch 157/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2405 - accuracy: 0.9330 - val_loss: 0.2672 - val_accuracy: 0.9285\n",
            "Epoch 158/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2404 - accuracy: 0.9330 - val_loss: 0.2667 - val_accuracy: 0.9282\n",
            "Epoch 159/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2405 - accuracy: 0.9335 - val_loss: 0.2669 - val_accuracy: 0.9284\n",
            "Epoch 160/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2402 - accuracy: 0.9336 - val_loss: 0.2672 - val_accuracy: 0.9283\n",
            "Epoch 161/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2401 - accuracy: 0.9326 - val_loss: 0.2679 - val_accuracy: 0.9286\n",
            "Epoch 162/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2402 - accuracy: 0.9332 - val_loss: 0.2675 - val_accuracy: 0.9287\n",
            "Epoch 163/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2398 - accuracy: 0.9332 - val_loss: 0.2682 - val_accuracy: 0.9277\n",
            "Epoch 164/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.9337 - val_loss: 0.2673 - val_accuracy: 0.9283\n",
            "Epoch 165/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2397 - accuracy: 0.9332 - val_loss: 0.2675 - val_accuracy: 0.9287\n",
            "Epoch 166/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2397 - accuracy: 0.9332 - val_loss: 0.2676 - val_accuracy: 0.9287\n",
            "Epoch 167/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2395 - accuracy: 0.9333 - val_loss: 0.2680 - val_accuracy: 0.9279\n",
            "Epoch 168/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2396 - accuracy: 0.9336 - val_loss: 0.2671 - val_accuracy: 0.9287\n",
            "Epoch 169/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.9333 - val_loss: 0.2669 - val_accuracy: 0.9293\n",
            "Epoch 170/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2393 - accuracy: 0.9334 - val_loss: 0.2684 - val_accuracy: 0.9281\n",
            "Epoch 171/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2394 - accuracy: 0.9338 - val_loss: 0.2673 - val_accuracy: 0.9280\n",
            "Epoch 172/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2393 - accuracy: 0.9333 - val_loss: 0.2676 - val_accuracy: 0.9287\n",
            "Epoch 173/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2392 - accuracy: 0.9333 - val_loss: 0.2669 - val_accuracy: 0.9293\n",
            "Epoch 174/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2390 - accuracy: 0.9338 - val_loss: 0.2688 - val_accuracy: 0.9282\n",
            "Epoch 175/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2390 - accuracy: 0.9334 - val_loss: 0.2683 - val_accuracy: 0.9281\n",
            "Epoch 176/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2389 - accuracy: 0.9336 - val_loss: 0.2672 - val_accuracy: 0.9278\n",
            "Epoch 177/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2387 - accuracy: 0.9338 - val_loss: 0.2675 - val_accuracy: 0.9292\n",
            "Epoch 178/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2389 - accuracy: 0.9334 - val_loss: 0.2674 - val_accuracy: 0.9295\n",
            "Epoch 179/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2386 - accuracy: 0.9335 - val_loss: 0.2677 - val_accuracy: 0.9282\n",
            "Epoch 180/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2385 - accuracy: 0.9337 - val_loss: 0.2675 - val_accuracy: 0.9287\n",
            "Epoch 181/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2384 - accuracy: 0.9340 - val_loss: 0.2674 - val_accuracy: 0.9292\n",
            "Epoch 182/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2384 - accuracy: 0.9340 - val_loss: 0.2684 - val_accuracy: 0.9279\n",
            "Epoch 183/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2384 - accuracy: 0.9336 - val_loss: 0.2689 - val_accuracy: 0.9279\n",
            "Epoch 184/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2383 - accuracy: 0.9336 - val_loss: 0.2674 - val_accuracy: 0.9287\n",
            "Epoch 185/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2383 - accuracy: 0.9335 - val_loss: 0.2675 - val_accuracy: 0.9282\n",
            "Epoch 186/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2381 - accuracy: 0.9337 - val_loss: 0.2695 - val_accuracy: 0.9279\n",
            "Epoch 187/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2380 - accuracy: 0.9336 - val_loss: 0.2675 - val_accuracy: 0.9293\n",
            "Epoch 188/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2380 - accuracy: 0.9337 - val_loss: 0.2678 - val_accuracy: 0.9287\n",
            "Epoch 189/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2379 - accuracy: 0.9336 - val_loss: 0.2683 - val_accuracy: 0.9290\n",
            "Epoch 190/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2377 - accuracy: 0.9342 - val_loss: 0.2683 - val_accuracy: 0.9285\n",
            "Epoch 191/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2377 - accuracy: 0.9336 - val_loss: 0.2692 - val_accuracy: 0.9270\n",
            "Epoch 192/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2375 - accuracy: 0.9336 - val_loss: 0.2685 - val_accuracy: 0.9281\n",
            "Epoch 193/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2377 - accuracy: 0.9344 - val_loss: 0.2687 - val_accuracy: 0.9281\n",
            "Epoch 194/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2375 - accuracy: 0.9343 - val_loss: 0.2684 - val_accuracy: 0.9278\n",
            "Epoch 195/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2374 - accuracy: 0.9339 - val_loss: 0.2684 - val_accuracy: 0.9279\n",
            "Epoch 196/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2375 - accuracy: 0.9342 - val_loss: 0.2679 - val_accuracy: 0.9286\n",
            "Epoch 197/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2371 - accuracy: 0.9338 - val_loss: 0.2690 - val_accuracy: 0.9262\n",
            "Epoch 198/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2371 - accuracy: 0.9342 - val_loss: 0.2678 - val_accuracy: 0.9285\n",
            "Epoch 199/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2372 - accuracy: 0.9338 - val_loss: 0.2692 - val_accuracy: 0.9273\n",
            "Epoch 200/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2372 - accuracy: 0.9341 - val_loss: 0.2683 - val_accuracy: 0.9289\n"
          ]
        }
      ],
      "source": [
        "#train the network\n",
        "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MpCg_YTMP17"
      },
      "source": [
        "**Looking at the results of the trained network**\n",
        "\n",
        "Let's evaluate the model to see how well it has learned ( or not) the MNIST problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZN9rro7KMP19",
        "outputId": "675cc74c-cc09-4f60-f7c6-d7d8832eb952",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.9256\n",
            "\n",
            "Test score/loss: 0.2692626118659973\n",
            "Test accuracy: 0.925599992275238\n"
          ]
        }
      ],
      "source": [
        "#test the network using the generalisation test dataset\n",
        "score = model.evaluate(input_X_test, output_Y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score/loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZuRJvfwMP2K"
      },
      "source": [
        "Training the Multi-Layer Perceptron\n",
        "=========\n",
        "**Defining the network: Multi-Layer Perceptron**\n",
        "\n",
        "We will now create a multi-layer perceptron with 784 input units, two hidden layers with 128 hidden units each, and an output layer with the 10 units.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HoF0ib-SMP2N",
        "outputId": "8477b6ea-4f20-4b61-942d-3df0f038496c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "N_EPOCH = 20 # we need fewer epoch than before, as the multi-layer percetpron can learn faster.\n",
        "N_HIDDEN = 128\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Hidden layer 1 with 128 hidden units and ReLu activation function\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "# Hidden layer 2 with 128 hidden units and ReLu activation function\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# output layer with 10 units and softmax activation\n",
        "model.add(Dense(N_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Summary of the whole model\n",
        "model.summary()\n",
        "\n",
        "# model compilation\n",
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgYzi3hyMP2V"
      },
      "source": [
        "**Let's train the mulri-layer perceptron network**\n",
        "\n",
        "Let's now train (fit) the network with the above-defined batch size (128), and number of epochs (20)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iNa3cmoaMP2X",
        "outputId": "435e74d9-27a1-4572-9676-33e5423bede5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 4s 8ms/step - loss: 0.4974 - accuracy: 0.8601 - val_loss: 0.2545 - val_accuracy: 0.9280\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2359 - accuracy: 0.9310 - val_loss: 0.1960 - val_accuracy: 0.9459\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1785 - accuracy: 0.9481 - val_loss: 0.1659 - val_accuracy: 0.9523\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1445 - accuracy: 0.9579 - val_loss: 0.1396 - val_accuracy: 0.9614\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1222 - accuracy: 0.9645 - val_loss: 0.1250 - val_accuracy: 0.9651\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1048 - accuracy: 0.9692 - val_loss: 0.1213 - val_accuracy: 0.9654\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0914 - accuracy: 0.9734 - val_loss: 0.1116 - val_accuracy: 0.9686\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0816 - accuracy: 0.9765 - val_loss: 0.1068 - val_accuracy: 0.9708\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0725 - accuracy: 0.9790 - val_loss: 0.1034 - val_accuracy: 0.9718\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0648 - accuracy: 0.9816 - val_loss: 0.0991 - val_accuracy: 0.9713\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0583 - accuracy: 0.9829 - val_loss: 0.0939 - val_accuracy: 0.9737\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0525 - accuracy: 0.9852 - val_loss: 0.0944 - val_accuracy: 0.9733\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0466 - accuracy: 0.9864 - val_loss: 0.1080 - val_accuracy: 0.9691\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9882 - val_loss: 0.0902 - val_accuracy: 0.9737\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.9894 - val_loss: 0.0879 - val_accuracy: 0.9762\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.9907 - val_loss: 0.0880 - val_accuracy: 0.9747\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0313 - accuracy: 0.9913 - val_loss: 0.0946 - val_accuracy: 0.9735\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0282 - accuracy: 0.9928 - val_loss: 0.0920 - val_accuracy: 0.9743\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0253 - accuracy: 0.9937 - val_loss: 0.0891 - val_accuracy: 0.9748\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.0883 - val_accuracy: 0.9753\n"
          ]
        }
      ],
      "source": [
        "#train the network\n",
        "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV5v4LNjMP2e"
      },
      "source": [
        "**Looking at the results of the trained network**\n",
        "\n",
        "Let's explotre the results both for the score and accuracy values, as well as to visualise the plots of these values during the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CXpu8p9uMP2f",
        "outputId": "7a5bfb8b-714e-4803-f441-d6bc64a79d83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0735 - accuracy: 0.9772\n",
            "\n",
            "Test score/loss: 0.07345282286405563\n",
            "Test accuracy: 0.9771999716758728\n"
          ]
        }
      ],
      "source": [
        "#test the network\n",
        "score = model.evaluate(input_X_test, output_Y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score/loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yYRZkVf6MP2t",
        "outputId": "27462111-e506-4f84-c32c-503e3a37d912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MJ9YbKviMP2z",
        "outputId": "93218319-a466-4f98-eb31-c2facabdabe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV-aShF1MP24"
      },
      "source": [
        "**Adding weight droputs**\n",
        "\n",
        "An efficient way to reduce the number of parameters (weights) to be trained, as well as to increase generalisation capabilities, is to randomly remove (i.e. __dropout__) a certain proportion of the nodes at random in each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4GNrMiVoMP25",
        "outputId": "a40cd69b-2e5e-4a63-f894-081281b34987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# import the dropout layer type\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Probability of weights dropout\n",
        "P_DROPOUT = 0.3\n",
        "\n",
        "# We can increse this parameter afterwards\n",
        "N_EPOCH = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(P_DROPOUT))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(P_DROPOUT))\n",
        "model.add(Dense(N_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# model compilation\n",
        "model.summary()\n",
        "\n",
        "# model compilation\n",
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBJJWwueMP2-"
      },
      "source": [
        "**Let's train the multi-layer perceptron network with DROPOUT**\n",
        "\n",
        "Let's now train (fit) the above dropout network with the above-defined batch size (128), and number of epochs (250)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Xqa-9UHxMP3A",
        "outputId": "cdfbeedc-9c28-42fc-a1a2-838e2e397c42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.6919 - accuracy: 0.7872 - val_loss: 0.2683 - val_accuracy: 0.9227\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.3419 - accuracy: 0.8996 - val_loss: 0.1998 - val_accuracy: 0.9420\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2731 - accuracy: 0.9199 - val_loss: 0.1668 - val_accuracy: 0.9516\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2343 - accuracy: 0.9310 - val_loss: 0.1495 - val_accuracy: 0.9566\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.2091 - accuracy: 0.9390 - val_loss: 0.1353 - val_accuracy: 0.9602\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1861 - accuracy: 0.9451 - val_loss: 0.1250 - val_accuracy: 0.9628\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1709 - accuracy: 0.9495 - val_loss: 0.1171 - val_accuracy: 0.9653\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1578 - accuracy: 0.9539 - val_loss: 0.1125 - val_accuracy: 0.9674\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1485 - accuracy: 0.9567 - val_loss: 0.1078 - val_accuracy: 0.9673\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1411 - accuracy: 0.9577 - val_loss: 0.1010 - val_accuracy: 0.9698\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1322 - accuracy: 0.9612 - val_loss: 0.0981 - val_accuracy: 0.9709\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1279 - accuracy: 0.9617 - val_loss: 0.0950 - val_accuracy: 0.9720\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1216 - accuracy: 0.9637 - val_loss: 0.0941 - val_accuracy: 0.9722\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1159 - accuracy: 0.9660 - val_loss: 0.0925 - val_accuracy: 0.9719\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1107 - accuracy: 0.9669 - val_loss: 0.0902 - val_accuracy: 0.9742\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1067 - accuracy: 0.9675 - val_loss: 0.0890 - val_accuracy: 0.9741\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1031 - accuracy: 0.9686 - val_loss: 0.0862 - val_accuracy: 0.9754\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0974 - accuracy: 0.9701 - val_loss: 0.0862 - val_accuracy: 0.9747\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0977 - accuracy: 0.9696 - val_loss: 0.0861 - val_accuracy: 0.9747\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0928 - accuracy: 0.9704 - val_loss: 0.0862 - val_accuracy: 0.9758\n"
          ]
        }
      ],
      "source": [
        "#train the network\n",
        "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-z1NP88MP3I"
      },
      "source": [
        "**Looking at the results of the trained dropout network**\n",
        "\n",
        "Let's explore the effects of adding the weight dropout on the network performance.\n",
        "\n",
        "You can see that the dropout has further improved our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K8qIacDmMP3N",
        "outputId": "abbb52c6-4900-498a-d3cc-8219ed1f48b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0785 - accuracy: 0.9768\n",
            "\n",
            "Test score: 0.07851002365350723\n",
            "Test accuracy: 0.9768000245094299\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#test the network\n",
        "score = model.evaluate(input_X_test, output_Y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IUIcenlMP3S"
      },
      "source": [
        "Exploring Training Hyperparameters\n",
        "-------------\n",
        "\n",
        "You can explore the role of various hyperparameters to see how you can further improve the MLP model's performance on the MNIST dataset. \n",
        "\n",
        "For example, if you increase the number of epochs for the dropout network to 250, you will see that the test and train accuracy errors will converge (accuracy closer to 97% for both training and test), which means that we have achieved the best tradeoff between training and testing.\n",
        "\n",
        "You can carry out many additional simulations on hypeparameter exploration where you can try for example:\n",
        "\n",
        "- different number of epochs\n",
        "- different learning rate\n",
        "- different number of hidden nodes \n",
        "- different proportion of dropout rates \n",
        "- different optimisers in addition to SGD (e.g. RMSprop, Adam) \n",
        "- different batch size \n",
        "\n",
        "This final exercise will constitute the first neural network coursework. See Coursework specification documenty for more details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPKj5NAdMP3T"
      },
      "source": [
        "Conclusions\n",
        "-------------\n",
        "\n",
        "With this tutorial we have practiced the training of both a Simple Perceptron, and a Multi-Layer Perceptron, with a benchmark dataset containing images of handwritten numbers.\n",
        "This helped us understand how to load the datase, visualise it, and visualise the training history and the effects of adding hidden layers and then adding weight dropout.\n",
        "\n",
        "**Copyright (c)** 2022 Angelo Cangelosi, MIT License. Code and examples adapted from Gulli & Pal (2017) Deep Learning with Keras. Punkt Publishing. With further contribution from Wenjie Huang."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}